{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Python Helpful codes","text":""},{"location":"#contents","title":"Contents","text":"<ol> <li>CLI (Command Line Interface)<ol> <li>Argument Parser</li> </ol> </li> </ol>"},{"location":"01-cli/01-argument-parser/","title":"Argument Parser in Python","text":""},{"location":"01-cli/01-argument-parser/#python-argparse-concise-notes","title":"Python argparse - Concise Notes","text":"<p><code>argparse</code> is a Python library for parsing command-line arguments. It provides a simple interface to define, process, and handle arguments.</p>"},{"location":"01-cli/01-argument-parser/#basic-usage","title":"Basic Usage","text":"<ol> <li> <p>Setup <pre><code>import argparse\nparser = argparse.ArgumentParser(description=\"A simple script\")\n</code></pre></p> </li> <li> <p>Adding Arguments</p> </li> <li> <p>Positional Argument: Required, order matters      <pre><code>parser.add_argument(\"filename\", help=\"File to process\")\n</code></pre></p> </li> <li> <p>Optional Argument: Starts with <code>--</code> or <code>-</code>, order doesn\u2019t matter.      <pre><code>parser.add_argument(\"--verbose\", action=\"store_true\", help=\"Enable verbose output\")\nparser.add_argument(\"-n\", \"--number\", type=int, default=1, help=\"Number of iterations\")\n</code></pre></p> </li> <li> <p>Parsing Arguments</p> </li> </ol> <pre><code>args = parser.parse_args()\nprint(args.filename)      # Positional argument\nprint(args.verbose)       # True/False (store_true)\nprint(args.number)        # Integer value (default: 1)\n</code></pre>"},{"location":"01-cli/01-argument-parser/#key-argument-settings","title":"Key Argument Settings","text":"<ol> <li>Positional Arguments:</li> <li>No special prefix.</li> <li> <p>Example: <code>python script.py input.txt</code></p> </li> <li> <p>Optional Arguments:</p> </li> <li>Use <code>-</code> or <code>--</code>.</li> <li> <p>Example: <code>python script.py --verbose</code></p> </li> <li> <p>Argument Types:</p> </li> <li>Specify with <code>type</code> (e.g., <code>int</code>, <code>float</code>, <code>str</code>).</li> <li> <p>Example:      <pre><code>parser.add_argument(\"--value\", type=float, help=\"A float value\")\n</code></pre></p> </li> <li> <p>Default Values:</p> </li> <li>Use <code>default</code>.</li> <li> <p>Example:      <pre><code>parser.add_argument(\"--name\", default=\"User\", help=\"Default name\")\n</code></pre></p> </li> <li> <p>Boolean Flags:</p> </li> <li>Use <code>action=\"store_true\"</code> or <code>action=\"store_false\"</code>.</li> <li> <p>Example:</p> <pre><code>parser.add_argument(\"--debug\", action=\"store_true\", help=\"Enable debug mode\")\n</code></pre> </li> </ol>"},{"location":"01-cli/01-argument-parser/#example-usage","title":"Example Usage","text":"<p>Script:</p> <pre><code>import argparse\n\nparser = argparse.ArgumentParser(description=\"Demo script\")\nparser.add_argument(\"filename\", help=\"Input file name\")\nparser.add_argument(\"-v\", \"--verbose\", action=\"store_true\", help=\"Enable verbosity\")\nparser.add_argument(\"-n\", \"--number\", type=int, default=10, help=\"Number of items\")\nargs = parser.parse_args()\n\nprint(f\"Filename: {args.filename}\")\nprint(f\"Verbose: {args.verbose}\")\nprint(f\"Number: {args.number}\")\n</code></pre> <p>Run:</p> <pre><code>python script.py file.txt --verbose -n 5\n</code></pre> <p>Output:</p> <pre><code>Filename: file.txt\nVerbose: True\nNumber: 5\n</code></pre>"},{"location":"01-cli/01-argument-parser/#common-methods","title":"Common Methods","text":"<ol> <li><code>parser.add_argument()</code>: Define arguments.</li> <li><code>parser.parse_args()</code>: Parse command-line inputs.</li> </ol>"},{"location":"01-cli/01-argument-parser/#tips","title":"Tips","text":"<ul> <li>Use <code>help</code> for clear CLI documentation.</li> <li>Default type is <code>str</code> if not specified.</li> <li>Boolean flags (<code>store_true</code>) are ideal for toggles.</li> </ul> <p>For most cases, this basic usage suffices!</p>"},{"location":"02-data-structures/01-map-filter-reduce-lambda/","title":"Map, Filter, Reduce and Lambda","text":""},{"location":"02-data-structures/01-map-filter-reduce-lambda/#map","title":"Map","text":"<ul> <li><code>map</code> applies a function to all the items in an input list, and returns new list.</li> </ul> <pre><code>def double(x):\n    return x * 2\n\nnumbers = [1, 2, 3, 4, 5]\ndoubles = list(map(double, numbers))\nprint(doubles)  # [2, 4, 6, 8, 10]\n</code></pre>"},{"location":"02-data-structures/01-map-filter-reduce-lambda/#filter","title":"Filter","text":"<ul> <li><code>filter</code> creates a list of elements for which a function returns <code>True</code>.</li> </ul> <pre><code>def is_even(x):\n    return x % 2 == 0\n\nnumbers = [1, 2, 3, 4, 5]\nevens = list(filter(is_even, numbers))\nprint(evens)  # [2, 4]\n</code></pre>"},{"location":"02-data-structures/01-map-filter-reduce-lambda/#reduce","title":"Reduce","text":"<ul> <li><code>reduce</code> applies a rolling computation to sequential pairs of values in a list.</li> </ul> <pre><code>from functools import reduce\n\ndef add(x, y):\n    return x + y\n\nnumbers = [1, 2, 3, 4, 5]\nsum = reduce(add, numbers)\nprint(sum)  # 15\n</code></pre>"},{"location":"02-data-structures/01-map-filter-reduce-lambda/#lambda","title":"Lambda","text":"<ul> <li><code>lambda</code> is an anonymous function that can have any number of arguments, but can have only one expression.</li> </ul> <pre><code>double = lambda x: x * 2\nprint(double(5))  # 10\n</code></pre>"},{"location":"02-data-structures/01-map-filter-reduce-lambda/#using-lambda-function-with-map","title":"Using lambda function with map","text":"<pre><code>numbers = [1, 2, 3, 4, 5]\ndoubles = list(map(lambda x: x * 2, numbers))\nprint(doubles)  # [2, 4, 6, 8, 10]\n</code></pre>"},{"location":"03-concurrency/03-concurrent-executor/","title":"Concurrent.futures in Python","text":"<ul> <li>High level API for asynchronously executing callables</li> <li>Provides:<ul> <li>Base class: Executor</li> <li>ThreadPool Executor</li> <li>ProcessPool Executor</li> </ul> </li> </ul>"},{"location":"03-concurrency/03-concurrent-executor/#executor-class","title":"Executor class","text":"<ul> <li>Executor class is an abstract class that provides methods to execute callables asynchronously</li> <li> <p>It provides two methods:</p> <ul> <li>submit(): Schedules the callable to be executed and returns a Future object</li> <li>map(): Maps the callable to an iterable of callables and returns a generator of Future objects.</li> </ul> </li> <li> <p><code>future</code> object is returned by them. It represents the result of the asynchronous computation.</p> </li> <li><code>map()</code> function's future returns value in the order of the input iterable.</li> <li><code>submit() + as_completed</code> function's future returns value in the order of completion.</li> </ul>"},{"location":"03-concurrency/03-concurrent-executor/#code-example","title":"Code Example","text":"<ul> <li><code>submit() + as_completed()</code></li> </ul> <pre><code>from concurrent.futures import ThreadPoolExecutor, as_completed\nimport time\n\ndef task(n):\n    time.sleep(n)\n    return n * n\n\nif __name__ == \"__main__\":\n    inputs = [3, 1, 4]\n    with ThreadPoolExecutor(max_workers=3) as executor:\n        futures = [executor.submit(task, n) for n in inputs]\n        for future in as_completed(futures):\n            print(future.result())  # Output could be unordered: 1, 9, 16\n</code></pre> <ul> <li><code>map()</code></li> </ul> <pre><code>from concurrent.futures import ThreadPoolExecutor\nimport time\n\ndef task(n):\n    time.sleep(n)  # Simulate variable execution time\n    return n * n\n\nif __name__ == \"__main__\":\n    inputs = [3, 1, 4]\n    with ThreadPoolExecutor(max_workers=3) as executor:\n        results = executor.map(task, inputs)  # Results will be in the order of `inputs`\n\n    for result in results:\n        print(result)  # Output: [9, 1, 16]\n</code></pre>"},{"location":"03-concurrency/01-threading/01-intro/","title":"Multithreading in Python","text":""},{"location":"03-concurrency/01-threading/01-intro/#threads","title":"Threads","text":"<ul> <li>Smallest unit of execution</li> <li>A process can have multiple threads</li> </ul>"},{"location":"03-concurrency/01-threading/01-intro/#types-of-threads","title":"Types of threads","text":"<ol> <li>Main Thread  : The initial thread of execution when the program starts.</li> <li>Daemon Threads  : Background threads that automatically exit when the main thread terminates.</li> <li>Non-Daemon Threads  : Threads that continue to run until they complete their task, even if the main thread exits.</li> </ol>"},{"location":"03-concurrency/01-threading/01-intro/#simple-threading-code","title":"Simple <code>threading</code> code","text":"<p>Info</p> <ul> <li><code>target</code> is the function to be executed</li> <li><code>args</code> is the argument to be passed to the function</li> <li><code>start</code> starts the thread</li> <li><code>join</code> waits for the thread to finish</li> </ul> <pre><code>import threading\n\n\ndef print_cube(num):\n    print(\"Cube: {}\" .format(num * num * num))\n\n\ndef print_square(num):\n    print(\"Square: {}\" .format(num * num))\n\n\nif __name__ ==\"__main__\":\n    t1 = threading.Thread(target=print_square, args=(10,))\n    t2 = threading.Thread(target=print_cube, args=(10,), daemon=True) # daemon thread\n\n    t1.start()\n    t2.start()\n\n    t1.join()\n    t2.join()\n\n    print(\"Done!\")\n</code></pre>"},{"location":"03-concurrency/01-threading/01-intro/#daemon-threads","title":"Daemon Threads","text":"<ul> <li>By passing <code>daemon=True</code> to the thread, we can make it a daemon thread.</li> <li>Daemon threads are background threads that automatically exit when the main thread terminates.</li> <li>Since daemon threads are abruptly terminated when the program ends, they may not finish their work or clean up resources properly. So, they are ideal for tasks that don't require cleanup or finishing. (like <code>logging</code>, <code>monitoring</code>, etc.)</li> </ul>"},{"location":"03-concurrency/01-threading/01-intro/#threads-name-pid","title":"Thread's name &amp; PID","text":"<ul> <li>all the threads that we will create, will have the same PID.</li> </ul> <pre><code>import threading\nimport os\n\ndef task1():\n    print(\"Task 1 assigned to thread: {}\".format(threading.current_thread().name))\n    print(\"ID of process running task 1: {}\".format(os.getpid()))\n\ndef task2():\n    print(\"Task 2 assigned to thread: {}\".format(threading.current_thread().name))\n    print(\"ID of process running task 2: {}\".format(os.getpid()))\n\nif __name__ == \"__main__\":\n\n    print(\"ID of process running main program: {}\".format(os.getpid()))\n\n    print(\"Main thread name: {}\".format(threading.current_thread().name))\n\n    t1 = threading.Thread(target=task1, name='t1')\n    t2 = threading.Thread(target=task2, name='t2')\n\n    t1.start()\n    t2.start()\n\n    t1.join()\n    t2.join()\n</code></pre>"},{"location":"03-concurrency/01-threading/01-intro/#simple-methods-of-threading-module","title":"Simple methods of <code>threading</code> module","text":"<ul> <li><code>active_count()</code> : Returns the number of Thread objects currently alive.</li> <li><code>current_thread()</code> : Returns the current Thread object, corresponding to the caller's thread of control.</li> <li><code>enumerate()</code> : Returns a list of all Thread objects currently alive.</li> <li><code>main_thread()</code> : Returns the main Thread object.</li> </ul> <pre><code>import threading\n\nprint(\"Number of active threads: {}\".format(threading.active_count()))\nprint(\"Current thread: {}\".format(threading.current_thread()))\nprint(\"List of all threads: {}\".format(threading.enumerate()))\nprint(\"Main thread: {}\".format(threading.main_thread()))\n</code></pre>"},{"location":"03-concurrency/01-threading/02-custom-thread/","title":"Custom Thread","text":"<p>creating custom thread</p> <ul> <li>We can inherit <code>Thread</code> class and create our own implementation of <code>run</code> method.</li> <li>We only need to implement <code>__init__</code> and <code>run</code> method.</li> <li>Then, we can use <code>start</code>, <code>join</code> and other methods as we did with <code>thread</code> class.</li> </ul> <pre><code>from threading import Thread\n\nclass MyThread(Thread):\n    def __init__(self, num):\n        self.num = num\n        super().__init__() # calling the parent class constructor (required)\n\n    def run(self):\n        for i in range(10):\n            print(f\"I'm thread: {self.num} =&gt; {i}\")\n\nif __name__ == \"__main__\":\n    my_t = []\n    for i in range(5):\n        curr_t = MyThread(i+1)\n        my_t.append(curr_t)\n\n    print(\"=== start all the threads ===\")\n    for t in my_t:\n        t.start()\n\n    for t in my_t:\n        t.join()\n\n    print(\"=== all threads finished ===\")\n</code></pre>"},{"location":"03-concurrency/01-threading/02-custom-thread/#make-custom-daemon-thread","title":"Make custom daemon thread","text":"<ul> <li>to make the thread <code>a daemon thread</code>, we can set <code>daemon=True</code> in the constructor.</li> </ul> <pre><code>super().__init__(daemon=True)\n</code></pre>"},{"location":"03-concurrency/01-threading/02-custom-thread/#methods-of-thread","title":"Methods of Thread","text":"<ol> <li><code>start</code>: This method starts the thread.</li> <li><code>join(timeout=None)</code>: This method waits infinitely for the thread to finish.</li> <li> <p><code>join(timeout)</code>: This method waits for the thread to finish for the specified time. <code>join()</code> method always return <code>None</code>. So to check if the <code>join() method</code> completed bcoz task is over, or due to timeout, we can use <code>is_alive()</code> method.</p> </li> <li> <p>If <code>is_alive()</code> returns <code>True</code>, then the thread is still running, and timeout has occurred (if <code>join(timeout)</code> is completed).</p> </li> </ol>"},{"location":"03-concurrency/01-threading/03-event/","title":"Event in Threading","text":"<ul> <li>communication mechanism b/w threads</li> </ul> <p>one thread signals an event and other threads wait for it.</p> <p>An event object manages an internal flag that can be:</p> <ul> <li>set to <code>true</code> with the <code>set() method</code></li> <li><code>is_set()</code> return True if and only if the internal flag is true.</li> <li>and <code>reset</code> to false with the <code>clear() method</code>.</li> <li>The <code>wait(timeout=None)</code> method blocks until the flag is true.</li> <li>If timeout of wait is not None (a floating point), it will wait for the flag to be set for the specified time, and then return <code>True</code> if the flag is set, otherwise <code>False</code>.</li> </ul>"},{"location":"03-concurrency/01-threading/03-event/#code","title":"Code","text":"<ul> <li>A sample code:</li> </ul> <pre><code>from threading import Thread, Event\nimport time\nimport threading\n\n# Create an Event object\nevent = Event()\n\n# Function that waits for the event to be set\ndef worker():\n    print(f\"Worker is waiting for the event...{event.is_set()=}\")\n    event.wait()  # Wait until the event is set\n    print(f\"Worker is proceeding! {event.is_set=}\")\n\n# Start a thread that runs the worker function\nthread = Thread(target=worker)\nthread.start()\n\n# Simulate some delay\ntime.sleep(2)\nprint(\"Main thread setting the event!\")\nevent.set()  # Signal the worker to proceed\n</code></pre>"},{"location":"03-concurrency/02-processing/01-intro/","title":"Multiprocessing in Python","text":"<ul> <li>Utilize multiple processors to speed up your code</li> <li>Escaping the GIL</li> <li><code>multiprocessing's process</code> is analogous to <code>threading's thread</code>. They hvae similar APIs.</li> </ul>"},{"location":"03-concurrency/02-processing/01-intro/#methods-to-start-new-process","title":"Methods to start new process","text":"<p><code>multiprocessing</code> supports three ways to start a process:</p> <ul> <li>Fork: Creates a new process by copying the parent, making it the fastest but potentially risky due to shared resources (UNIX only). <code>Fork is fast, potentially unsafe, and may carry unnecessary data from the parent, though Copy-On-Write mitigates this</code>.</li> <li>Spawn: Starts a clean process from scratch, ensuring safety and isolation but at the cost of slower startup (default on Windows). <code>While slower, this is the safest option, especially for long-running or resource-sensitive tasks</code>.</li> <li>Forkserver: Uses a dedicated server to spawn processes, combining safety with moderate performance overhead (UNIX only). <code>Though less commonly used due to setup complexity and limited documentation, it\u2019s useful for controlled multi-process environments</code>.</li> </ul>"},{"location":"03-concurrency/02-processing/01-intro/#set-get-process-start-method","title":"Set &amp; Get <code>process start method</code>","text":"<ul> <li>To select a start method you use the <code>set_start_method()</code> in the if <code>__name__ == '__main__'</code> clause of the main module.</li> </ul> <pre><code>import multiprocessing as mp\n\nprint(mp.get_start_method())  # Get the current start method\n\nif __name__ == '__main__':\n    mp.set_start_method('forkserver')  # Set the start method\n</code></pre> <ul> <li>set_start_method() should not be used more than once in the program.</li> </ul>"},{"location":"03-concurrency/02-processing/01-intro/#simple-multiprocessing-example","title":"Simple multiprocessing example","text":"<pre><code># importing the multiprocessing module\nfrom multiprocessing import Process\nimport os\n\ndef print_cube(num):\n    \"\"\"\n    function to print cube of given num\n    \"\"\"\n    print(\"Cube: {}; and {}\".format(num * num * num, os.getpid()))\n\ndef print_square(num):\n    \"\"\"\n    function to print square of given num\n    \"\"\"\n    print(\"Square: {}; and {}\".format(num * num, os.getpid()))\n\nif __name__ == \"__main__\":\n    # creating processes\n    p1 = Process(target=print_square, args=(10, ))\n    p2 = Process(target=print_cube, args=(10, ))\n\n    # starting process 1\n    p1.start()\n    # starting process 2\n    p2.start()\n\n    # wait until process 1 is finished\n    p1.join()\n    # wait until process 2 is finished\n    p2.join()\n\n    # both processes finished\n    print(\"Done!\")\n</code></pre> <p>Info</p> <p><code>Process</code> has very similar API to <code>Thread</code> in <code>threading</code> module.</p> <ul> <li><code>start()</code>, <code>join()</code>, <code>is_alive()</code>, etc.</li> <li><code>Process</code> also provides a <code>terminal()</code> and <code>kill()</code> method to terminate a process.</li> <li><code>target</code> is the function to be executed by the process.</li> <li><code>args</code> is the arguments to be passed to the target function.</li> </ul> <p></p>"},{"location":"03-concurrency/02-processing/02-communication/","title":"Communication in Multiprocessing","text":"<ul> <li>Processes can push values to a queue and pull values from a queue(<code>most important</code>).</li> <li>Two processes can communicate with each other using a pipe.</li> <li>Processes can share memory using shared memory objects. If one process changes the value, the other process can see the change.</li> </ul>"},{"location":"03-concurrency/02-processing/02-communication/#shared-memory","title":"Shared Memory","text":""},{"location":"03-concurrency/02-processing/02-communication/#value","title":"<code>Value</code>","text":"<ul> <li><code>Value</code> is a shared memory object that allows you to store a single value.</li> <li>Specify the type of the value and the initial value.</li> <li>Read and write the value using the <code>value</code> attribute.</li> </ul>"},{"location":"03-concurrency/02-processing/02-communication/#array","title":"<code>Array</code>","text":"<ul> <li><code>Array</code> is a shared memory object that allows you to store a sequence of values.</li> <li>Specify the type of the value and the length.</li> </ul> <pre><code>from multiprocessing import Process, Value, Array\n\ndef f(n, a):\n    n.value = 3.1415927\n    for i in range(len(a)):\n        a[i] = -a[i]\n\nif __name__ == '__main__':\n    num = Value('d', 0.0)\n    arr = Array('i', range(10))\n\n    p = Process(target=f, args=(num, arr))\n    p.start()\n    p.join()\n\n    print(num.value)\n    print(arr[:])\n</code></pre>"},{"location":"03-concurrency/02-processing/02-communication/#queue","title":"Queue","text":"<ul> <li><code>Queue</code> is a thread and process-safe queue.</li> <li>It allows multiple processes to push and pull values from the queue.</li> </ul> <pre><code>from multiprocessing import Process, Queue\n\ndef f(q):\n    q.put([42, None, 'hello'])\n\nif __name__ == '__main__':\n    q = Queue()\n    p = Process(target=f, args=(q,))\n    p.start()\n    print(q.get())    # prints \"[42, None, 'hello']\"\n    p.join()\n</code></pre> <p>methods of Queue</p> <ul> <li><code>put(obj, block=True, timeout=None)</code>: Push a value to the queue. If queue is full, block and wait until the queue doesn't have any space, then push. If timeout is not None, it will wait for the specified time, and then raise <code>queue.Full</code> exception if the queue is still full.</li> <li><code>put_nowait(obj)</code>: Push a value to the queue. If the queue is full, raise <code>queue.Full</code> exception.</li> <li><code>get(block=True, timeout=None)</code>: Pull a value from the queue. If no value is available, block and wait until a value is available. If timeout is not None, it will wait for the specified time, and then raise <code>queue.Empty</code> exception if the queue is still empty.</li> <li><code>get_nowait()</code>: Pull a value from the queue. If no value is available, raise <code>queue.Empty</code> exception.</li> <li><code>empty()</code>: Return <code>True</code> if the queue is empty.</li> <li><code>full()</code>: Return <code>True</code> if the queue is full.</li> <li><code>qsize()</code>: Return the number of items in the queue.</li> <li><code>close()</code>: Close the queue.</li> <li><code>join_thread()</code>: Join the background thread. This can only be used after close() has been called. It blocks until the background thread exits, ensuring that all data in the buffer has been flushed to the pipe.</li> </ul>"},{"location":"03-concurrency/02-processing/02-communication/#pipe","title":"Pipe","text":"<ul> <li><code>Pipe</code> is a two-way communication channel between two processes.</li> <li>It returns two connection objects that represent the two ends of the pipe.</li> <li>Both connection objects have <code>send()</code> and <code>recv()</code> methods.</li> <li>data in a pipe may become corrupted if two processes (or threads) try to read from or write to the same end of the pipe at the same time.</li> <li>Of course there is no risk of corruption from processes using different ends of the pipe at the same time.</li> </ul> <pre><code>from multiprocessing import Process, Pipe\n\ndef f(conn):\n    conn.send([42, None, 'hello'])\n    conn.close()\n\nif __name__ == '__main__':\n    parent_conn, child_conn = Pipe()\n    p = Process(target=f, args=(child_conn,))\n    p.start()\n    print(parent_conn.recv())   # prints \"[42, None, 'hello']\"\n    p.join()\n</code></pre> <ul> <li>Each connection object (<code>parent_conn</code> &amp; <code>child_conn</code>) returned by pipe have multiple ways to transfer data.</li> </ul> <p>connection object methods</p> <ul> <li><code>send()</code>: Send data to the other end of the pipe.</li> <li><code>recv()</code>: Receive data from the other end of the pipe.</li> <li><code>poll(timeout=None)</code>: Return <code>True</code> if there is any data to read.</li> <li><code>send_bytes(buffer)</code>: Send a bytes object.</li> <li><code>recv_bytes(maxlength)</code>: Receive a bytes object.</li> <li><code>recv_bytes_into(buffer)</code>: Receive a bytes object into a buffer.</li> </ul> <pre><code>&gt;&gt;&gt; from multiprocessing import Pipe\n&gt;&gt;&gt;\n&gt;&gt;&gt; a, b = Pipe()\n&gt;&gt;&gt;\n&gt;&gt;&gt; a.send([1, 'hello', None])\n&gt;&gt;&gt; b.recv()\n[1, 'hello', None]\n&gt;&gt;&gt;\n&gt;&gt;&gt; b.send_bytes(b'thank you')\n&gt;&gt;&gt; a.recv_bytes()\nb'thank you'\n&gt;&gt;&gt;\n&gt;&gt;&gt; import array\n&gt;&gt;&gt;\n&gt;&gt;&gt; arr1 = array.array('i', range(5))\n&gt;&gt;&gt; arr2 = array.array('i', [0] * 10)\n&gt;&gt;&gt;\n&gt;&gt;&gt; a.send_bytes(arr1)\n&gt;&gt;&gt; count = b.recv_bytes_into(arr2)\n&gt;&gt;&gt; assert count == len(arr1) * arr1.itemsize\n&gt;&gt;&gt; arr2\narray('i', [0, 1, 2, 3, 4, 0, 0, 0, 0, 0])\n</code></pre>"},{"location":"03-concurrency/02-processing/03-locking/","title":"Locking &amp; Event in Multiprocessing","text":""},{"location":"03-concurrency/02-processing/03-locking/#lock","title":"Lock","text":"<ul> <li><code>Lock</code> is a synchronization primitive that allows only one process to access a shared resource at a time.</li> <li>it has two methods <code>acquire(block=True, timeout=None)</code> and <code>release()</code>.</li> </ul> <pre><code>from multiprocessing import Process, Lock\n\ndef f(l, i):\n    l.acquire()\n    try:\n        print('hello world', i)\n    finally:\n        l.release()\n\nif __name__ == '__main__':\n    lock = Lock()\n\n    for num in range(10):\n        Process(target=f, args=(lock, num)).start()\n</code></pre>"},{"location":"03-concurrency/02-processing/03-locking/#lock-with-context-manager","title":"Lock with context manager","text":"<ul> <li>Lock can also be used as a context manager.</li> <li>It automatically acquires the lock before the block and releases it after the block.</li> </ul> <pre><code>from multiprocessing import Process, Lock\n\ndef f(l, i):\n    with l:\n        print('hello world', i)\n\nif __name__ == '__main__':\n    lock = Lock()\n\n    for num in range(10):\n        Process(target=f, args=(lock, num)).start()\n</code></pre>"},{"location":"03-concurrency/02-processing/03-locking/#event","title":"Event","text":"<ul> <li>Similar to threading, <code>Event</code> is a communication mechanism between processes.</li> <li>one process signals an event and other process wait for it.</li> </ul> <p>An event object manages an internal flag that can be:</p> <ul> <li>set to <code>true</code> with the <code>set() method</code></li> <li><code>is_set()</code> return True if and only if the internal flag is true.</li> <li>and <code>reset</code> to false with the <code>clear() method</code>.</li> <li>The <code>wait(timeout=None)</code> method blocks until the flag is true.</li> <li>If timeout of wait is not None (a floating point), it will wait for the flag to be set for the specified time, and then return <code>True</code> if the flag is set, otherwise <code>False</code>.</li> </ul>"},{"location":"03-concurrency/02-processing/03-locking/#event-object-in-multiprocessing-are-not-shared-bw-processes","title":"Event object in multiprocessing are not shared b/w processes \u274c\ud83d\udc47\ud83c\udffb","text":"<pre><code>from multiprocessing import Process, Event\nimport time\nimport multiprocessing\n\n# Create an Event object\nevent = Event()\n\n# Function that waits for the event to be set\ndef worker():\n    print(f\"Worker is waiting for the event...{event.is_set()=}\")\n    event.wait()  # Wait until the event is set\n    print(f\"Worker is proceeding! {event.is_set=}\")\n\n# Start a thread that runs the worker function\np = Process(target=worker)\np.start()\n\n# Simulate some delay\ntime.sleep(2)\nprint(\"Main thread setting the event!\")\nevent.set()  # Signal the worker to proceed\n</code></pre> <p>Event object in multiprocessing are not shared b/w processes</p> <p>The above code will not work as expected. The event object is not shared between processes. The worker process will not be able to see the event set by the main process.</p> <ul> <li>We need to use <code>manager.Event()</code> to create an event object that is shared between processes.</li> </ul>"},{"location":"03-concurrency/02-processing/03-locking/#multiprocessing-manager","title":"Multiprocessing manager","text":"<pre><code>from multiprocessing import Process, Event, Manager\nimport time\n\ndef worker(event):\n    print(f\"Worker is waiting for the event...{event.is_set()=}\")\n    event.wait()  # Wait until the event is set\n    print(f\"Worker is proceeding! {event.is_set()=}\")\n\nif __name__ == \"__main__\":\n    with Manager() as manager:\n        # Create a shared Event object\n        event = manager.Event()\n\n        # Start a process that runs the worker function\n        p = Process(target=worker, args=(event,))\n        p.start()\n\n        # Simulate some delay\n        time.sleep(2)\n        print(\"Main process setting the event!\")\n        event.set()  # Signal the worker to proceed\n        p.join()\n</code></pre>"},{"location":"03-concurrency/02-processing/04-manager/","title":"Manager in Python Multiprocessing","text":""},{"location":"03-concurrency/02-processing/04-manager/#what-is-a-manager","title":"What is a Manager?","text":"<ul> <li>A <code>Manager</code> in Python's <code>multiprocessing</code> module provides a way to create and manage shared objects between processes.</li> <li>Shared objects include lists, dictionaries, Events, Locks, and more.</li> </ul>"},{"location":"03-concurrency/02-processing/04-manager/#why-use-a-manager","title":"Why Use a Manager?","text":"<ul> <li>Processes in Python have separate memory spaces.</li> <li>Without a <code>Manager</code>, objects created in one process are not automatically shared with others.</li> <li>A <code>Manager</code> allows processes to interact with shared objects safely.</li> </ul>"},{"location":"03-concurrency/02-processing/04-manager/#common-use-cases","title":"Common Use Cases","text":"<ol> <li>Sharing data structures like lists or dictionaries between processes.</li> <li>Synchronizing processes using shared objects like <code>Event</code> or <code>Lock</code>.</li> </ol>"},{"location":"03-concurrency/02-processing/04-manager/#how-to-use-a-manager","title":"How to Use a Manager?","text":""},{"location":"03-concurrency/02-processing/04-manager/#basic-syntax","title":"Basic Syntax","text":"<pre><code>from multiprocessing import Manager\n\nwith Manager() as manager:\n    shared_list = manager.list()  # Create a shared list\n    shared_dict = manager.dict()  # Create a shared dictionary\n</code></pre>"},{"location":"03-concurrency/02-processing/04-manager/#example-shared-dictionary","title":"Example: Shared Dictionary","text":"<pre><code>from multiprocessing import Process, Manager\n\ndef worker(shared_dict):\n    shared_dict[\"key\"] = \"value\"  # Update the shared dictionary\n\nif __name__ == \"__main__\":\n    with Manager() as manager:\n        shared_dict = manager.dict()  # Create a shared dictionary\n        p = Process(target=worker, args=(shared_dict,))\n        p.start()\n        p.join()\n        print(shared_dict)  # Output: {'key': 'value'}\n</code></pre>"},{"location":"03-concurrency/02-processing/04-manager/#example-shared-event","title":"Example: Shared Event","text":"<pre><code>from multiprocessing import Process, Manager\n\ndef worker(event):\n    print(\"Waiting for event...\")\n    event.wait()  # Wait for the event to be set\n    print(\"Event is set!\")\n\nif __name__ == \"__main__\":\n    with Manager() as manager:\n        event = manager.Event()  # Create a shared Event\n        p = Process(target=worker, args=(event,))\n        p.start()\n        event.set()  # Set the event\n        p.join()\n</code></pre>"},{"location":"03-concurrency/02-processing/04-manager/#advantages","title":"Advantages","text":"<ul> <li>Provides easy sharing of objects across processes.</li> <li>Manages synchronization safely and avoids manual complexity.</li> </ul>"},{"location":"03-concurrency/02-processing/04-manager/#disadvantages","title":"Disadvantages","text":"<ul> <li>Slower than using shared memory (e.g., <code>multiprocessing.Value</code> or <code>multiprocessing.Array</code>) because communication is handled via a server process.</li> <li>Overhead for small or frequent updates.</li> </ul>"},{"location":"03-concurrency/02-processing/04-manager/#when-to-use-a-manager","title":"When to Use a Manager?","text":"<ul> <li>Use a <code>Manager</code> when you need to share complex data structures or synchronization primitives like <code>Event</code> or <code>Lock</code>.</li> <li>For performance-critical tasks with simple data, prefer shared memory objects.</li> </ul>"},{"location":"03-concurrency/02-processing/05-process-pool/","title":"Process Pools in Python Multiprocessing","text":""},{"location":"03-concurrency/02-processing/05-process-pool/#what-is-a-process-pool","title":"What is a Process Pool?","text":"<ul> <li>A <code>ProcessPool</code> is a pool of worker processes used to execute tasks concurrently.</li> <li>It simplifies the management of multiple processes, especially when there are many tasks to distribute.</li> </ul>"},{"location":"03-concurrency/02-processing/05-process-pool/#why-use-a-process-pool","title":"Why Use a Process Pool?","text":"<ul> <li>To execute tasks in parallel across multiple processes without manually managing them.</li> <li>To reuse worker processes, reducing the overhead of creating and destroying processes repeatedly.</li> <li>Provides an easy-to-use interface for parallel execution.</li> </ul>"},{"location":"03-concurrency/02-processing/05-process-pool/#key-methods-of-process-pools","title":"Key Methods of Process Pools","text":"<ol> <li><code>apply()</code>: Executes a single task in a process and waits for the result (blocking).</li> <li><code>apply_async()</code>: Executes a single task asynchronously and returns a <code>AsyncResult</code> object (non-blocking).</li> <li><code>map()</code>: Distributes an iterable of tasks across processes and collects results (blocking).</li> <li><code>map_async()</code>: Same as <code>map()</code> but non-blocking.</li> <li><code>starmap()</code>: Similar to <code>map()</code> but supports multiple arguments for each task. <code>map doesn't support multiple argument</code>.</li> <li><code>imap()</code>: Lazily returns an iterator to results as they become available.</li> </ol>"},{"location":"03-concurrency/02-processing/05-process-pool/#how-to-use-a-process-pool","title":"How to Use a Process Pool?","text":""},{"location":"03-concurrency/02-processing/05-process-pool/#basic-syntax","title":"Basic Syntax","text":"<pre><code>from multiprocessing import Pool\n\nwith Pool(processes=4) as pool:  # Create a pool with 4 worker processes\n    result = pool.map(func, iterable)\n</code></pre>"},{"location":"03-concurrency/02-processing/05-process-pool/#examples","title":"Examples","text":""},{"location":"03-concurrency/02-processing/05-process-pool/#1-using-map","title":"1. Using <code>map()</code>","text":"<pre><code>from multiprocessing import Pool\n\ndef square(x):\n    return x * x\n\nif __name__ == \"__main__\":\n    with Pool(processes=4) as pool:\n        results = pool.map(square, [1, 2, 3, 4])\n    print(results)  # Output: [1, 4, 9, 16]\n</code></pre>"},{"location":"03-concurrency/02-processing/05-process-pool/#2-using-apply_async","title":"2. Using <code>apply_async()</code>","text":"<pre><code>from multiprocessing import Pool\n\ndef cube(x):\n    return x ** 3\n\nif __name__ == \"__main__\":\n    with Pool(processes=2) as pool:\n        result = pool.apply_async(cube, (3,))\n        print(result.get())  # Output: 27\n</code></pre>"},{"location":"03-concurrency/02-processing/05-process-pool/#3-using-starmap","title":"3. Using <code>starmap()</code>","text":"<pre><code>from multiprocessing import Pool\n\ndef add(a, b):\n    return a + b\n\nif __name__ == \"__main__\":\n    with Pool(processes=2) as pool:\n        results = pool.starmap(add, [(1, 2), (3, 4), (5, 6)])\n    print(results)  # Output: [3, 7, 11]\n</code></pre>"},{"location":"03-concurrency/02-processing/05-process-pool/#map-vs-imap-vs-imap_unordered","title":"Map Vs iMap vs imap_unordered","text":"<p>The <code>imap()</code> function in Python's <code>multiprocessing.Pool</code> is a variant of <code>map()</code> that processes tasks lazily, meaning it returns an iterator instead of a fully-evaluated list. This can be beneficial when working with large datasets because results are produced and consumed one at a time, avoiding the need to store all results in memory at once.</p>"},{"location":"03-concurrency/02-processing/05-process-pool/#key-differences-between-map-and-imap","title":"Key Differences Between <code>map()</code> and <code>imap()</code>","text":"Feature <code>map()</code> <code>imap()</code> Return Type List (eager evaluation) Iterator (lazy evaluation) Memory Usage Stores all results in memory Produces results one at a time Use Case Small-to-medium datasets Large datasets where memory is a concern"},{"location":"03-concurrency/02-processing/05-process-pool/#example-of-imap","title":"Example of <code>imap()</code>","text":"<pre><code>from multiprocessing import Pool\nimport time\n\ndef slow_square(x):\n    time.sleep(1)  # Simulate a slow computation\n    return x * x\n\nif __name__ == \"__main__\":\n    with Pool(processes=2) as pool:\n        results = pool.imap(slow_square, [1, 2, 3, 4, 5])\n\n        # Process results as they are ready\n        for result in results:\n            print(result)\n</code></pre>"},{"location":"03-concurrency/02-processing/05-process-pool/#output-one-result-every-second","title":"Output (one result every second):","text":"<pre><code>1\n4\n9\n16\n25\n</code></pre>"},{"location":"03-concurrency/02-processing/05-process-pool/#why-use-imap","title":"Why Use <code>imap()</code>?","text":"<ul> <li>Memory Efficiency:  </li> </ul> <p>Instead of generating and storing all results at once, <code>imap()</code> produces them incrementally. Useful when working with large input datasets or when the task is memory-intensive.</p> <ul> <li>Time Efficiency:  </li> </ul> <p>If you want to start processing results as they are computed, <code>imap()</code> enables this instead of waiting for all tasks to complete like <code>map()</code>.</p>"},{"location":"03-concurrency/02-processing/05-process-pool/#variants","title":"Variants:","text":"<ul> <li><code>imap_unordered()</code>:</li> <li>Similar to <code>imap()</code> but does not preserve the order of results.</li> <li>Results are returned as soon as individual tasks are completed, regardless of their order in the input.</li> <li> <p>Useful for maximizing throughput when the order of results doesn't matter.</p> </li> </ul> <pre><code>with Pool(processes=2) as pool:\n    results = pool.imap_unordered(slow_square, [1, 2, 3, 4, 5])\n    for result in results:\n        print(result)  # Results might appear out of order\n</code></pre>"},{"location":"03-concurrency/02-processing/05-process-pool/#example","title":"Example","text":""},{"location":"03-concurrency/02-processing/05-process-pool/#advantages","title":"Advantages","text":"<ul> <li>Simplifies parallel execution of tasks.</li> <li>Automatically handles process management (creation, destruction, and task distribution).</li> <li>Efficient for CPU-bound tasks that benefit from parallelism.</li> </ul>"},{"location":"03-concurrency/02-processing/05-process-pool/#disadvantages","title":"Disadvantages","text":"<ul> <li>Limited to functions (cannot directly use methods tied to objects).</li> <li>Overhead in creating and managing the pool can be significant for very lightweight tasks.</li> </ul>"},{"location":"03-concurrency/02-processing/05-process-pool/#when-to-use-a-process-pool","title":"When to Use a Process Pool?","text":"<ul> <li>Use a <code>ProcessPool</code> for independent, parallelizable tasks that are CPU-bound and can benefit from multiple processes.</li> <li>Avoid using it for I/O-bound tasks\u2014for such tasks, consider using ThreadPoolExecutor or asynchronous programming.</li> </ul>"},{"location":"03-concurrency/02-processing/06-custom-process/","title":"Custom Process","text":""},{"location":"03-concurrency/02-processing/06-custom-process/#why-create-a-custom-process","title":"Why Create a Custom Process?","text":"<ul> <li>Subclassing <code>multiprocessing.Process</code> is useful when you need to encapsulate specific data or behavior for each process. (Like LitData DataWorker, a process class that downloads data, processes it, and saves it to a database.)</li> <li>Allows defining a custom <code>run()</code> method, which will be executed when the process starts.</li> </ul>"},{"location":"03-concurrency/02-processing/06-custom-process/#implementation","title":"Implementation \ud83e\udd13","text":"<p>creating custom process</p> <ul> <li>Very similar to <code>creating custom thread</code>.</li> <li>We can inherit <code>Process</code> class and create our own implementation of <code>run</code> method.</li> <li>We only need to implement <code>__init__</code> and <code>run</code> method.</li> <li>Then, we can use <code>start</code>, <code>join</code> and other methods as we did with <code>Process</code> class.</li> </ul> <pre><code>from multiprocessing import Process\n\nclass MyProcess(Process):\n    def __init__(self, num):\n        self.num = num\n        super().__init__() # calling the parent class constructor (required)\n\n    def run(self):\n        for i in range(10):\n            print(f\"I'm process: {self.num} =&gt; {i}\")\n\nif __name__ == \"__main__\":\n    my_p = []\n    for i in range(5):\n        curr_p = MyProcess(i+1)\n        my_p.append(curr_p)\n\n    print(\"=== start all the processes ===\")\n    for p in my_p:\n        p.start()\n\n    for p in my_p:\n        p.join()\n\n    print(\"=== all processes finished ===\")\n</code></pre>"},{"location":"04-network-and-ipc/01-async/01-intro/","title":"AsyncIO","text":"<ul> <li>asyncio is a library to write concurrent code using the async/await syntax.</li> </ul> <p>asyncio is often a perfect fit for IO-bound and high-level structured network code.</p>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/","title":"High-Level APIs of <code>asyncio</code>","text":"<p><code>asyncio</code> is Python's library for asynchronous programming, allowing you to run tasks concurrently without using threads or processes.</p>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#key-concepts","title":"Key Concepts","text":""},{"location":"04-network-and-ipc/01-async/02-high-level-api/#1-coroutine","title":"1. Coroutine","text":"<ul> <li>A function defined using <code>async def</code>.</li> <li>Can be paused and resumed using <code>await</code>.</li> <li>Example:</li> </ul> <pre><code>async def my_coroutine():\n    await asyncio.sleep(1)  # Pause for 1 second\n    print(\"Done!\")\n</code></pre>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#2-event-loop","title":"2. Event Loop","text":"<ul> <li>Manages the execution of coroutines and tasks.</li> <li>High-level APIs automatically handle the event loop for you.</li> </ul>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#3-task","title":"3. Task","text":"<ul> <li>A coroutine wrapped in a <code>Task</code> object, which runs concurrently.</li> <li>Created using <code>asyncio.create_task()</code>.</li> </ul>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#high-level-functions","title":"High-Level Functions","text":""},{"location":"04-network-and-ipc/01-async/02-high-level-api/#1-asyncioruncoro","title":"1. <code>asyncio.run(coro)</code>","text":"<ul> <li>Runs the given coroutine and closes the event loop after completion.</li> <li>Use it as the entry point for your asynchronous program.</li> <li>Example:</li> </ul> <pre><code>async def main():\n    print(\"Hello, asyncio!\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#2-asynciogathercoros","title":"2. <code>asyncio.gather(*coros)</code>","text":"<ul> <li>Runs multiple coroutines concurrently and collects their results.</li> <li>Results are returned in the same order as the coroutines were passed.</li> <li>Example:</li> </ul> <pre><code>async def task(name, delay):\n    await asyncio.sleep(delay)\n    return f\"Task {name} done\"\n\nasync def main():\n    results = await asyncio.gather(task(\"A\", 2), task(\"B\", 1))\n    print(results)  # Output: ['Task A done', 'Task B done']\n\nasyncio.run(main())\n</code></pre>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#3-asynciocreate_taskcoro","title":"3. <code>asyncio.create_task(coro)</code>","text":"<ul> <li>Starts a coroutine as a background task and returns a <code>Task</code> object.</li> <li>The task runs concurrently with other coroutines.</li> <li>Example:</li> </ul> <pre><code>async def task(name, delay):\n    await asyncio.sleep(delay)\n    print(f\"{name} finished\")\n\nasync def main():\n    t1 = asyncio.create_task(task(\"Task 1\", 2))\n    t2 = asyncio.create_task(task(\"Task 2\", 1))\n    await t1\n    await t2\n\nasyncio.run(main())\n</code></pre>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#4-await-asynciosleepseconds","title":"4. <code>await asyncio.sleep(seconds)</code>","text":"<ul> <li>Asynchronously pauses execution for the given number of seconds.</li> <li>Allows other tasks to run during the pause.</li> <li>Example:</li> </ul> <pre><code>async def main():\n    print(\"Start\")\n    await asyncio.sleep(1)\n    print(\"End after 1 second\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#error-handling","title":"Error Handling","text":""},{"location":"04-network-and-ipc/01-async/02-high-level-api/#catching-exceptions-in-gather","title":"Catching Exceptions in <code>gather</code>","text":"<ul> <li>Use <code>try/except</code> around <code>asyncio.gather()</code> to catch exceptions from any coroutine.</li> <li>Example:</li> </ul> <pre><code>async def faulty_task():\n    raise ValueError(\"Something went wrong\")\n\nasync def main():\n    try:\n        await asyncio.gather(faulty_task())\n    except Exception as e:\n        print(f\"Caught exception: {e}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#return_exceptionstrue-in-gather","title":"<code>return_exceptions=True</code> in <code>gather</code>","text":"<ul> <li>Collect exceptions without canceling other tasks.</li> <li>Example:</li> </ul> <pre><code>async def faulty_task():\n    raise ValueError(\"Something went wrong\")\n\nasync def main():\n    results = await asyncio.gather(\n        faulty_task(),\n        asyncio.sleep(1),\n        return_exceptions=True\n    )\n    print(results)  # Output: [ValueError('Something went wrong'), None]\n\nasyncio.run(main())\n</code></pre>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#common-patterns","title":"Common Patterns","text":""},{"location":"04-network-and-ipc/01-async/02-high-level-api/#run-coroutines-concurrently","title":"Run Coroutines Concurrently","text":"<p>Use <code>gather</code> or <code>create_task</code> for concurrency:</p> <pre><code>async def task1():\n    await asyncio.sleep(2)\n    print(\"Task 1 done\")\n\nasync def task2():\n    await asyncio.sleep(1)\n    print(\"Task 2 done\")\n\nasync def main():\n    await asyncio.gather(task1(), task2())  # Runs both tasks concurrently\n\nasyncio.run(main())\n</code></pre>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#cancel-a-task","title":"Cancel a Task","text":"<pre><code>async def main():\n    task = asyncio.create_task(asyncio.sleep(10))\n    await asyncio.sleep(1)\n    task.cancel()  # Cancels the task\n    try:\n        await task\n    except asyncio.CancelledError:\n        print(\"Task was cancelled!\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#summary","title":"Summary","text":"<ol> <li>Use <code>async def</code> and <code>await</code> to define and run coroutines.</li> <li>Use <code>asyncio.run</code> to execute your main coroutine.</li> <li>Use <code>asyncio.gather</code> or <code>create_task</code> for concurrency.</li> <li>Handle errors with <code>try/except</code> or <code>return_exceptions=True</code>.</li> </ol>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/","title":"Low-Level Overview of <code>asyncio</code>","text":"<p>The low-level APIs in <code>asyncio</code> provide finer control over the event loop, tasks, and protocols. These are useful for advanced use cases like integrating <code>asyncio</code> with custom frameworks or building servers.</p>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/#key-low-level-apis","title":"Key Low-Level APIs","text":""},{"location":"04-network-and-ipc/01-async/03-low-level-api/#1-event-loop","title":"1. Event Loop","text":"<ul> <li>The event loop manages the execution of asynchronous tasks and handles I/O.</li> <li>Use <code>asyncio.get_event_loop()</code> or <code>asyncio.new_event_loop()</code> to work with it.</li> <li>Example:</li> </ul> <pre><code>import asyncio\n\nasync def main():\n    print(\"Running in the event loop\")\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(main())  # Manually run the coroutine\nloop.close()  # Always close the loop when done\n</code></pre>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/#2-future","title":"2. Future","text":"<ul> <li>A placeholder for a result that hasn\u2019t been computed yet.</li> <li>Usually created internally by <code>asyncio</code>, but you can use it manually.</li> <li>Example:</li> </ul> <pre><code>import asyncio\n\nloop = asyncio.get_event_loop()\nfuture = loop.create_future()\n\n# Set the result of the future\nloop.call_soon(future.set_result, \"Result is ready\")\n\n# Get the result\nprint(loop.run_until_complete(future))  # Output: \"Result is ready\"\n</code></pre>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/#3-task","title":"3. Task","text":"<ul> <li>A <code>Task</code> is a coroutine that is being executed by the event loop.</li> <li>You can use <code>asyncio.create_task()</code> (high-level) or <code>loop.create_task()</code> (low-level) to create tasks.</li> <li>Example:</li> </ul> <pre><code>import asyncio\n\nasync def say_hello():\n    await asyncio.sleep(1)\n    print(\"Hello!\")\n\nloop = asyncio.get_event_loop()\ntask = loop.create_task(say_hello())  # Manually create a task\nloop.run_until_complete(task)\nloop.close()\n</code></pre>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/#4-custom-event-loop","title":"4. Custom Event Loop","text":"<ul> <li>You can create and manage a custom event loop for advanced use cases.</li> <li>Example:</li> </ul> <pre><code>import asyncio\n\nasync def my_task():\n    await asyncio.sleep(1)\n    print(\"Task completed!\")\n\n# Create a new event loop\ncustom_loop = asyncio.new_event_loop()\nasyncio.set_event_loop(custom_loop)\n\ncustom_loop.run_until_complete(my_task())\ncustom_loop.close()\n</code></pre>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/#low-level-tasks-management","title":"Low-Level Tasks Management","text":""},{"location":"04-network-and-ipc/01-async/03-low-level-api/#1-loopcall_soon","title":"1. <code>loop.call_soon()</code>","text":"<ul> <li>Schedules a callback to be executed as soon as possible.</li> <li>Example:</li> </ul> <pre><code>import asyncio\n\ndef my_callback():\n    print(\"Callback executed!\")\n\nloop = asyncio.get_event_loop()\nloop.call_soon(my_callback)\nloop.run_forever()  # Will execute the callback and then keep running\n</code></pre>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/#2-loopcall_later","title":"2. <code>loop.call_later()</code>","text":"<ul> <li>Schedules a callback to be executed after a specific delay.</li> <li>Example:</li> </ul> <pre><code>import asyncio\n\ndef delayed_callback():\n    print(\"Callback executed after delay!\")\n\nloop = asyncio.get_event_loop()\nloop.call_later(2, delayed_callback)  # 2-second delay\nloop.run_forever()\n</code></pre>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/#custom-futures-and-tasks","title":"Custom Futures and Tasks","text":""},{"location":"04-network-and-ipc/01-async/03-low-level-api/#1-using-asynciofuture","title":"1. Using <code>asyncio.Future</code>","text":"<ul> <li>Create your own placeholder for asynchronous results.</li> <li>Example:</li> </ul> <pre><code>import asyncio\n\ndef set_future_result(future):\n    future.set_result(\"Future is done!\")\n\nloop = asyncio.get_event_loop()\nfuture = asyncio.Future()\n\nloop.call_soon(set_future_result, future)\nprint(loop.run_until_complete(future))  # Output: \"Future is done!\"\n</code></pre>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/#2-running-coroutines-as-tasks","title":"2. Running Coroutines as Tasks","text":"<ul> <li>Coroutines need to be wrapped in a <code>Task</code> for the event loop to execute them.</li> <li>Example:</li> </ul> <pre><code>import asyncio\n\nasync def my_task():\n    print(\"Task running...\")\n    await asyncio.sleep(1)\n    print(\"Task finished!\")\n\nloop = asyncio.get_event_loop()\ntask = asyncio.ensure_future(my_task())  # Wrap coroutine in a Task\nloop.run_until_complete(task)\n</code></pre>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/#usage","title":"Usage","text":"<pre><code>async def set_after(fut, delay, value):\n    # Sleep for *delay* seconds.\n    await asyncio.sleep(delay)\n\n    # Set *value* as a result of *fut* Future.\n    fut.set_result(value)\n\nasync def main():\n    # Get the current event loop.\n    loop = asyncio.get_running_loop()\n\n    # Create a new Future object.\n    fut = loop.create_future()\n\n    # Run \"set_after()\" coroutine in a parallel Task.\n    # We are using the low-level \"loop.create_task()\" API here because\n    # we already have a reference to the event loop at hand.\n    # Otherwise we could have just used \"asyncio.create_task()\".\n    loop.create_task(\n        set_after(fut, 1, '... world'))\n\n    print('hello ...')\n\n    # Wait until *fut* has a result (1 second) and print it.\n    print(await fut)\n\nasyncio.run(main())\n</code></pre>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/#error-handling-in-low-level-apis","title":"Error Handling in Low-Level APIs","text":""},{"location":"04-network-and-ipc/01-async/03-low-level-api/#handle-task-exceptions","title":"Handle Task Exceptions","text":"<ul> <li>Example:</li> </ul> <pre><code>import asyncio\n\nasync def faulty_task():\n    raise ValueError(\"Oops!\")\n\nloop = asyncio.get_event_loop()\ntask = loop.create_task(faulty_task())\n\ntry:\n    loop.run_until_complete(task)\nexcept ValueError as e:\n    print(f\"Caught exception: {e}\")\n</code></pre>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/#summary","title":"Summary","text":"<ul> <li>Low-level APIs are for fine-grained control, like managing custom event loops or working with protocols and transports.</li> <li>Use Futures to represent pending results, and Tasks to run coroutines concurrently.</li> <li>Low-level APIs are generally for advanced use cases; stick to high-level APIs for most tasks.</li> </ul>"},{"location":"04-network-and-ipc/01-async/04-async-event/","title":"Async Event (<code>Synchronization Primitives</code>)","text":"<ul> <li>An asyncio event can be used to notify multiple asyncio tasks that some event has happened.</li> </ul> <p>An Event object manages an internal flag that can be set to true with the set() method and reset to false with the clear() method.</p> <p>The wait() method blocks until the flag is set to true. The flag is set to false initially.</p> <pre><code>import asyncio\n\nasync def waiter(event):\n    print('waiting for it ...')\n    await event.wait()\n    print('... got it!')\n\nasync def main():\n    # Create an Event object.\n    event = asyncio.Event()\n\n    # Spawn a Task to wait until 'event' is set.\n    waiter_task = asyncio.create_task(waiter(event))\n\n    # Sleep for 1 second and set the event.\n    await asyncio.sleep(1)\n    event.set()\n\n    # Wait until the waiter task is finished.\n    await waiter_task\n\nasyncio.run(main())\n</code></pre>"}]}